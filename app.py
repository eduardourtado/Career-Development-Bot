import streamlit as st
import os 
from google import genai
from google.genai.errors import APIError
from google.genai.types import Content, Part
from fpdf.fpdf import FPDF # Importa√ß√£o expl√≠cita para fpdf2
from datetime import datetime

# --- Fun√ß√£o de Limpeza de Estado ---
def clear_session_state():
    """Reinicia todas as vari√°veis de estado da sess√£o."""
    st.session_state["messages"] = [{"role": "system", "content": ""}] 
    st.session_state.pdi_state = 0 
    st.session_state.configs = {} 
    st.session_state.start_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    if 'generate_summary' in st.session_state:
        del st.session_state['generate_summary']


# --- 1. Configura√ß√£o da Interface ---
st.set_page_config(page_title="Mentor de Carreira PDI (Gemini)", page_icon="üéØ", layout="centered")

st.title("üéØ Mentor de PDI Inteligente (Gemini)")
st.markdown("Ol√°! Sou seu assistente de carreira. Vamos construir seu **Plano de Desenvolvimento Individual** juntos. Por favor, responda o formul√°rio inicial para um planejamento eficaz.")

# --- CSS para Layout Preto/Branco e Estabilidade ---
st.markdown("""
<style>
    /* 1. Estilos de Cores */
    .stApp {background-color: #000000; color: #FFFFFF;}
    h1, h2, h3, h4, p, .stMarkdown {color: #FFFFFF !important;}
    
    /* 2. Largura e Padding */
    .block-container {padding-top: 2rem; padding-bottom: 0rem; padding-left: 2rem; padding-right: 2rem; max-width: 800px;}
    
    /* 3. Estilo das Caixas de Mensagem */
    .stChatMessage {border-radius: 15px; padding: 15px; background-color: #1A1A1A; color: #FFFFFF !important; border: 1px solid #444444;}
    
    /* 4. Estilo da Barra de Input de Mensagem */
    .stTextInput > div > div > input, .stTextInput > label {
        color: #FFFFFF; background-color: #000000; border: 1px solid #FFFFFF; border-radius: 8px;
    }
    
    /* 5. CORRE√á√ÉO DE LEGIBILIDADE PARA ST.RADIO E ST.SELECT */
    .stRadio > label, .stRadio > div > label > div > div > p {
        color: #FFFFFF !important; 
    }
    
    /* 7. OCULTA BARRAS DE CABE√áALHO E RODAP√â */
    header {visibility: hidden; height: 0px;}
    footer {visibility: hidden; height: 0px;}
    #MainMenu {visibility: hidden;}
    
    /* 8. Estilo padr√£o para Bot√µes (Download) */
    div.stButton > button {
        background-color: #4A90E2; /* Fundo Azul */
        color: #FFFFFF; /* Texto Branco */
        border: none;
        border-radius: 5px; 
        padding: 10px 15px;
        cursor: pointer;
    }
    
    /* 9. ESTILO CR√çTICO PARA O BOT√ÉO DO FORMUL√ÅRIO (PRETO COM TEXTO BRANCO) */
    div[data-testid="stForm"] div.stButton button {
        color: #FFFFFF !important; /* Texto Branco */
        background-color: #000000 !important; /* Fundo Preto */
        border: 2px solid #FFFFFF !important; /* Borda Branca vis√≠vel */
        box-shadow: 0 0 5px rgba(255, 255, 255, 0.5); /* Sombra para destaque */
    }
    
    /* 10. GARANTE que o span (o texto interno) tamb√©m seja branco */
    div[data-testid="stForm"] div.stButton button span {
        color: #FFFFFF !important; 
    }
    
</style>
""", unsafe_allow_html=True)


# --- 2. Vari√°veis de Estado e Perguntas PERSONALIZADAS ---
QUESTION_FLOW = [
    # Bloco 1: Configura√ß√µes (st.radio)
    {"type": "intro", "text": "Antes de come√ßarmos, vamos configurar o **idioma e o estilo de resposta** do nosso Mentor. Isso garante uma comunica√ß√£o perfeita!"},
    {"type": "select", "question": "Em qual idioma voc√™ prefere que o Mentor de PDI responda?", 
     "key": "lang", "options": ["Portugu√™s", "Ingl√™s", "Espanhol"]},
    {"type": "select", "question": "Qual estilo de intera√ß√£o voc√™ prefere?", 
     "key": "style", "options": ["Extrovertido", "Profissional"]},
    {"type": "select", "question": "Voc√™ prefere respostas com mais ou menos detalhes?", 
     "key": "detail", "options": ["Muito Detalhe", "Direto ao Ponto"]},

    # Bloco 2: Sobre Voc√™ (st.chat_input)
    {"type": "intro", "text": "√ìtimo! Agora, come√ßarei fazendo algumas perguntas sobre voc√™. Tudo bem?"},
    {"type": "input", "question": "Como voc√™ preferiria que eu te chamasse?"},
    {"type": "input", "question": "Quantos anos voc√™ tem?"},

    # Bloco 3: Experi√™ncias Educacionais (st.chat_input)
    {"type": "intro", "text": "Perfeito. Agora, gostaria de explorarmos mais detalhes sobre suas **experi√™ncias educacionais**."},
    {"type": "input", "question": "Qual foi o maior n√≠vel de educa√ß√£o que voc√™ j√° obteve? (Ex: Bacharelado, Mestrado, P√≥s-doutorado)"},
    {"type": "input", "question": "Em qual institui√ß√£o voc√™ obteve essa forma√ß√£o?"},
    {"type": "input", "question": "Qual foi a sua √°rea de estudo?"},

    # Bloco 4: Experi√™ncia Profissional (st.chat_input)
    {"type": "intro", "text": "Entendido. Vamos agora para o bloco de **experi√™ncia profissional**."},
    {"type": "input", "question": "Voc√™ j√° trabalhou como jovem aprendiz? Se sim, em qual ano foi sua primeira experi√™ncia nesse formato?"},
    {"type": "input", "question": "Voc√™ j√° trabalhou como estagi√°rio(a)? Se sim, em qual ano foi sua primeira experi√™ncia nesse formato?"},
    {"type": "input", "question": "Voc√™ j√° trabalhou como funcion√°rio CLT? Se sim, em qual ano foi sua primeira experi√™ncia nesse formato?"},
    {"type": "input", "question": "Por favor, cite os nomes das empresas nas quais voc√™ j√° trabalhou como CLT (separe por v√≠rgulas)"},
    {"type": "input", "question": "Voc√™ est√° trabalhando atualmente? Se sim, cite qual √© o nome da sua posi√ß√£o e empresa atuais"},

    # Bloco 5: Objetivos Profissionais (st.chat_input)
    {"type": "intro", "text": "Para finalizar nosso formul√°rio, vamos focar nos seus **objetivos profissionais**."},
    {"type": "input", "question": "Quais s√£o os seus principais objetivos profissionais?"}
]
NUM_FLOW_STEPS = len(QUESTION_FLOW)

# --- 3. Carregamento Secreto da Chave ---
gemini_api_key = os.environ.get("GEMINI_API_KEY")

# --- 4. L√≥gica de Mem√≥ria (Hist√≥rico e Estado) ---
if "messages" not in st.session_state:
    clear_session_state() 

# --- FUN√á√ïES DE GERA√á√ÉO E DOWNLOAD ---

def get_user_name():
    """Busca o nome preferido do usu√°rio no hist√≥rico da conversa."""
    name_question = "Como voc√™ preferiria que eu te chamasse?"
    
    for msg in st.session_state.messages:
        if msg["role"] == "user" and name_question in msg["content"]:
            try:
                name = msg["content"].split(':')[-1].strip()
                if name:
                    return name
            except:
                pass
    return "Usu√°rio(a)" 

def format_transcript_data(messages):
    """Formata o hist√≥rico de mensagens em uma lista de tuplas (role, content)."""
    data = []
    user_name = get_user_name()
    for msg in messages[1:]:
        role = "Mentor" if msg["role"] == "model" else user_name
        data.append((role, msg["content"]))
    return data

def clean_and_encode_text(text):
    """
    Limpa o texto de Markdown e for√ßa a codifica√ß√£o latin-1 com 'replace'.
    Isso substitui emojis e caracteres tipogr√°ficos por um caractere seguro.
    """
    
    # 1. Limpa Markdown (resolve s√≠mbolos feios no PDF)
    clean = text.replace("`", "'").replace("**", "").replace("*", "")
    
    # 2. Garante que qualquer resqu√≠cio de emoji ou caractere complexo seja substitu√≠do
    return clean.encode('latin-1', 'replace').decode('latin-1')

def pdf_print_content(pdf, data):
    """
    Imprime o conte√∫do formatado no PDF com cores e negrito. 
    Cont√©m a corre√ß√£o cr√≠tica de encoding.
    """
    
    MENTOR_BLUE = (0, 100, 200)   
    USER_GREEN = (0, 150, 0)     
    WHITE = (255, 255, 255)      
    
    for role, content in data:
        # TRATAMENTO CR√çTICO: Limpeza e codifica√ß√£o antes de tocar o FPDF
        clean_content = clean_and_encode_text(content)

        # 1. Impress√£o do Cabe√ßalho do Turno
        if role == "Mentor":
            pdf.set_text_color(*MENTOR_BLUE)
            pdf.set_font("Helvetica", style="B", size=11)
        else:
            pdf.set_text_color(*USER_GREEN)
            pdf.set_font("Helvetica", style="B", size=11)
        
        pdf.cell(0, 8, f"üó£Ô∏è {role}:", ln=1) 

        # 2. Impress√£o do Conte√∫do (Texto Limpo)
        pdf.set_text_color(*WHITE)
        pdf.set_font("Helvetica", size=10)
        
        # MUDAN√áA CR√çTICA: For√ßa a convers√£o para bytes seguros ANTES de multi_cell
        # Isso impede que o FPDF quebre ao tentar codificar caracteres no final do documento.
        pdf.multi_cell(0, 5, clean_content.encode('latin-1', 'replace').decode('latin-1'))
        
        pdf.ln(2)

@st.cache_data(show_spinner="Gerando Resumo da Conversa com o Gemini...")
def generate_summary(history_messages, api_key):
    """Gera um resumo da conversa usando o Gemini."""
    if not api_key: return "Erro: Chave GEMINI_API_KEY n√£o configurada."
    try:
        client = genai.Client(api_key=api_key)
        history_contents = []
        for m in history_messages[1:]:
            role = 'user' if m['role'] == 'user' else 'model'
            content_obj = Content(role=role, parts=[Part.from_text(text=m['content'])]) 
            history_contents.append(content_obj)
        summary_prompt = "Voc√™ √© um Analista de Dados. Dada a conversa a seguir entre um Mentor de PDI e um Usu√°rio, gere um resumo profissional e conciso dos pontos principais, focando nas respostas do usu√°rio (experi√™ncias e objetivos) e na an√°lise/d√∫vidas do Mentor. USE APENAS TEXTO, SEM MARKDOWN OU S√çMBOLOS."
        history_contents.append(Content(role='user', parts=[Part.from_text(text=summary_prompt)]))
        response = client.models.generate_content(
            model='gemini-2.5-flash', 
            contents=history_contents
        )
        return response.text
    except APIError as e: 
        return f"Erro na API do Gemini ao gerar resumo: {e}"
    except Exception as e: 
        return f"Ocorreu um erro inesperado ao gerar resumo: {e}"

def generate_pdf_bytes(content_data, title_suffix, is_summary=False):
    """Gera o PDF com layout escuro, personalizado e estruturado."""
    
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=20)
    pdf.add_page()
    
    # --- 1. Fundo Preto (HACK) ---
    pdf.set_fill_color(0, 0, 0) # Preto RGB
    pdf.rect(0, 0, pdf.w, pdf.h, 'F') # Desenha um ret√¢ngulo preto em toda a p√°gina

    # --- 2. Cabe√ßalho Personalizado (Branco) ---
    pdf.set_text_color(255, 255, 255) # Branco
    pdf.set_font("Helvetica", style="B", size=18)
    pdf.cell(0, 10, "üéØ Mentor de PDI Inteligente (Gemini)", ln=1, align="C")
    
    pdf.set_font("Helvetica", style="I", size=12)
    pdf.cell(0, 7, title_suffix, ln=1, align="C")
    
    pdf.set_font("Helvetica", size=10)
    pdf.cell(0, 5, f"Data: {st.session_state.start_time}", ln=1, align="C")
    pdf.ln(8)
    
    # --- 3. Conte√∫do ---
    
    if is_summary:
        # Para Resumo: Limpa e imprime o texto diretamente
        pdf.set_text_color(255, 255, 255) 
        pdf.set_font("Helvetica", size=11)
        
        # TRATAMENTO CR√çTICO: Limpeza e codifica√ß√£o antes de tocar o FPDF
        clean_summary = clean_and_encode_text(content_data)
        
        # MUDAN√áA CR√çTICA: For√ßa a convers√£o para bytes seguros ANTES de multi_cell
        pdf.multi_cell(0, 6, clean_summary.encode('latin-1', 'replace').decode('latin-1'))
    else:
        # Para Transcri√ß√£o, usa a fun√ß√£o de impress√£o colorida
        pdf_print_content(pdf, content_data)
        
    # --- 4. Sa√≠da Final (Onde o erro ocorria) ---
    # FPDF.output() retorna uma string que precisa ser convertida em bytes.
    # Usamos o encode final com replace para capturar qualquer metadado que o fpdf2 falhe ao codificar.
    pdf_content_str = pdf.output(dest='S') 
    return pdf_content_str.encode('latin-1', 'replace')


# Fun√ß√£o que executa o submit do formul√°rio de sele√ß√£o
def submit_form(key, question):
    selected_option = st.session_state[f'select_{st.session_state.pdi_state}']

    # 1. Armazena a configura√ß√£o
    st.session_state.configs[key] = selected_option
    
    # 2. Registra a resposta do usu√°rio no hist√≥rico
    st.session_state.messages.append({"role": "user", "content": f"{question}: {selected_option}"})
    
    # 3. Avan√ßa o estado e for√ßa a reexecu√ß√£o
    st.session_state.pdi_state += 1 
    st.rerun() 


# Fun√ß√£o para montar o System Prompt baseado nas configura√ß√µes
def build_system_prompt():
    lang = st.session_state.configs.get('lang', 'Portugu√™s')
    style = st.session_state.configs.get('style', 'Profissional')
    detail = st.session_state.configs.get('detail', 'Muito Detalhe')
    
    return f"""
        Voc√™ √© um Mentor de Carreira S√™nior especializado em criar Planos de Desenvolvimento Individual (PDI).
        
        INSTRU√á√ïES DE COMPORTAMENTO R√çGIDAS:
        1. EDUCA√á√ÉO: Voc√™ **DEVE** ser sempre cort√™s, educado e profissional. **NUNCA** use linguagem passivo-agressiva ou grosseira, mesmo ao pedir esclarecimentos ou ao criticar objetivos.
        2. IDIOMA PRINCIPAL: Responda APENAS em {lang}.
        3. TOM E DETALHE: O tom de voz deve ser {style}. Se for 'Direto ao Ponto', use listas e par√°grafos curtos, mantendo a polidez.
        
        SUA MISS√ÉO:
        Voc√™ acaba de receber as respostas iniciais do usu√°rio. Revise, valide e inicie a fase de identifica√ß√£o de Gaps.
        """

# Fun√ß√£o para gerar o conte√∫do usando o Gemini
def generate_gemini_response(prompt, api_key):
    st.session_state.messages[0]['content'] = build_system_prompt()
    system_prompt = st.session_state.messages[0]['content']

    if not api_key: st.error("Erro de configura√ß√£o: A chave GEMINI_API_KEY n√£o foi encontrada."); return None
        
    try:
        client = genai.Client(api_key=api_key)
        
        history_messages = []
        for m in st.session_state.messages[1:]:
            role = 'user' if m['role'] == 'user' else 'model'
            content_obj = Content(role=role, parts=[Part.from_text(text=m['content'])]) 
            history_messages.append(content_obj)
        
        history_messages.append(Content(role='user', parts=[Part.from_text(text=prompt)]))

        response = client.models.generate_content(
            model='gemini-2.5-flash', 
            contents=history_messages, 
            config={'system_instruction': system_prompt} 
        )
        return response
    
    except APIError as e: st.error(f"Erro na API do Gemini: Detalhe: {e}"); return None
    except Exception as e: st.error(f"Ocorreu um erro inesperado: {e}"); return None


# --- 5. L√≥gica da M√°quina de Estados (Controle do Fluxo) ---

# Exibir mensagens anteriores no chat
for msg in st.session_state.messages:
    if msg["role"] != "system":
        role = 'assistant' if msg["role"] == 'model' else msg["role"]
        st.chat_message(role).write(msg["content"])


# L√≥gica para avan√ßar o formul√°rio ou iniciar o chat
if st.session_state.pdi_state < NUM_FLOW_STEPS:
    
    current_step = QUESTION_FLOW[st.session_state.pdi_state]
    
    # 5.1. Exibir Introdu√ß√£o E SALVAR NO HIST√ìRICO (corre√ß√£o de duplica√ß√£o)
    if current_step["type"] == "intro":
        intro_text = current_step["text"]
        st.chat_message("assistant").write(intro_text)
        
        if not st.session_state.messages or st.session_state.messages[-1]["content"] != intro_text:
            st.session_state.messages.append({"role": "model", "content": intro_text})
        
        st.session_state.pdi_state += 1
        st.rerun()

    # 5.2. Exibir M√∫ltipla Escolha (st.radio)
    elif current_step["type"] == "select":
        question_text = current_step["question"]
        st.chat_message("assistant").write(question_text)
        
        if not st.session_state.messages or st.session_state.messages[-1]["content"] != question_text:
            st.session_state.messages.append({"role": "model", "content": question_text})

        with st.form(key=f'form_{st.session_state.pdi_state}'):
            st.radio("Selecione uma op√ß√£o:", 
                     current_step["options"], 
                     key=f'select_{st.session_state.pdi_state}')
            
            st.form_submit_button(
                "Confirmar e Continuar", 
                on_click=submit_form, 
                kwargs={'key': current_step["key"], 'question': current_step["question"]}
            )
        
        st.stop() 

    # 5.3. Exibir Pergunta de Texto (st.chat_input)
    elif current_step["type"] == "input":
        question_text = current_step["question"]
        st.chat_message("assistant").write(question_text)

        if not st.session_state.messages or st.session_state.messages[-1]["content"] != question_text:
            st.session_state.messages.append({"role": "model", "content": question_text})


# 5.4. Captura a intera√ß√£o do usu√°rio e Finaliza
if prompt := st.chat_input("Digite sua resposta aqui..."):
    
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    if st.session_state.pdi_state < NUM_FLOW_STEPS:
        
        st.session_state.pdi_state += 1
        
        if st.session_state.pdi_state < NUM_FLOW_STEPS:
            st.rerun() 
        else:
            # Transi√ß√£o final para o Chat Ativo
            with st.chat_message("assistant"):
                st.markdown("‚úÖ **Formul√°rio inicial completo!** O Mentor de Carreira j√° est√° analisando suas respostas. Por favor, aguarde enquanto ele processa a primeira an√°lise e inicia a fase de identifica√ß√£o de *Gaps*.")
                
            final_prompt_to_gemini = st.session_state.messages[-1]['content']
            
            with st.chat_message("assistant"):
                response = generate_gemini_response(final_prompt_to_gemini, gemini_api_key)
                if response:
                    full_response = response.text
                    st.markdown(full_response)
                    st.session_state.messages.append({"role": "model", "content": full_response})
                else:
                    st.session_state.messages.pop()
    else:
        # 5.5. Chat Ativo (Gemini assume)
        with st.chat_message("assistant"):
            response = generate_gemini_response(prompt, gemini_api_key)
            
            if response:
                full_response = response.text
                st.markdown(full_response)
                
                st.session_state.messages.append({"role": "model", "content": full_response})
            else:
                st.session_state.messages.pop()

# --- 6. BOT√ïES DE A√á√ÉO E DOWNLOAD (Sempre Vis√≠veis na Sidebar) ---

st.sidebar.subheader("‚öôÔ∏è A√ß√µes")
st.sidebar.button("Limpar Conversa e Recome√ßar", on_click=clear_session_state) 
st.sidebar.markdown("---")


# Gera√ß√£o de PDF (vis√≠vel o tempo todo)
st.sidebar.subheader("üóÇÔ∏è Download do Hist√≥rico")

# Transcri√ß√£o Completa
transcript_data = format_transcript_data(st.session_state.messages)
pdf_full = generate_pdf_bytes(transcript_data, "Transcri√ß√£o Completa", is_summary=False)

st.sidebar.download_button(
    label="1Ô∏è‚É£ Transcri√ß√£o Completa (PDF)",
    data=pdf_full,
    file_name=f"PDI_Transcricao_{datetime.now().strftime('%Y%m%d')}.pdf",
    mime="application/pdf"
)

# Resumo
if st.sidebar.button("2Ô∏è‚É£ Gerar Resumo (PDF)"):
    
    if st.session_state.pdi_state < NUM_FLOW_STEPS:
        st.warning("Aguarde a conclus√£o do formul√°rio inicial para gerar um resumo significativo.")
    elif gemini_api_key:
        # Gera o resumo usando a fun√ß√£o cacheada
        summary_text = generate_summary(st.session_state.messages, gemini_api_key)
        
        if summary_text.startswith(("Erro:", "Ocorreu um erro")):
             st.error(summary_text)
        else:
            # O Resumo √© uma string simples, o PDF precisa saber que √© um resumo
            pdf_summary = generate_pdf_bytes(summary_text, "Resumo da An√°lise (Gemini)", is_summary=True)
            
            # Reexibe o bot√£o com os dados do PDF
            st.sidebar.download_button(
                label="‚úÖ Baixar Resumo Gerado",
                data=pdf_summary,
                file_name=f"PDI_Resumo_{datetime.now().strftime('%Y%m%d')}.pdf",
                mime="application/pdf"
            )
            st.success("Resumo gerado com sucesso! Clique para baixar.")
    else:
        st.error("Erro: A chave GEMINI_API_KEY n√£o est√° configurada.")
