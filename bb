import streamlit as st
import osÂ 
from google import genai
from google.genai.errors import APIError
from google.genai.types import Content, Part
from fpdf.fpdf import FPDFÂ 
from datetime import datetime

# --- FunÃ§Ã£o de Limpeza de Estado ---
def clear_session_state():
Â  Â  """Reinicia todas as variÃ¡veis de estado da sessÃ£o."""
Â  Â  st.session_state["messages"] = [{"role": "system", "content": ""}]Â 
Â  Â  st.session_state.pdi_state = 0Â 
Â  Â  st.session_state.configs = {}Â 
Â  Â  st.session_state.start_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
Â  Â  if 'generate_summary' in st.session_state:
Â  Â  Â  Â  del st.session_state['generate_summary']


# --- 1. ConfiguraÃ§Ã£o da Interface ---
st.set_page_config(page_title="Mentor de Carreira PDI (Gemini)", page_icon="ğŸ¯", layout="centered")

st.title("ğŸ¯ Mentor de PDI Inteligente (Gemini)")
st.markdown("OlÃ¡! Sou seu assistente de carreira. Vamos construir seu **Plano de Desenvolvimento Individual** juntos. Por favor, responda o formulÃ¡rio inicial para um planejamento eficaz.")

# --- CSS para Layout Preto/Branco e Estabilidade ---
st.markdown("""
<style>
Â  Â  /* ... CSS OMITIDO POR CONCISÃƒO ... */
Â  Â  .stApp {background-color: #000000; color: #FFFFFF;}
Â  Â  h1, h2, h3, h4, p, .stMarkdown {color: #FFFFFF !important;}
Â  Â  .block-container {padding-top: 2rem; padding-bottom: 0rem; padding-left: 2rem; padding-right: 2rem; max-width: 800px;}
Â  Â  .stChatMessage {border-radius: 15px; padding: 15px; background-color: #1A1A1A; color: #FFFFFF !important; border: 1px solid #444444;}
Â  Â  .stRadio > label, .stRadio > div > label > div > div > p {color: #FFFFFF !important;}
Â  Â  div.stButton > button {background-color: #4A90E2; color: #FFFFFF; border: none; border-radius: 5px; padding: 10px 15px; cursor: pointer;}
Â  Â  div[data-testid="stForm"] div.stButton button {
Â  Â  Â  Â  color: #FFFFFF !important;Â 
Â  Â  Â  Â  background-color: #000000 !important;Â 
Â  Â  Â  Â  border: 2px solid #FFFFFF !important;Â 
Â  Â  Â  Â  box-shadow: 0 0 5px rgba(255, 255, 255, 0.5);
Â  Â  }
Â  Â  div[data-testid="stForm"] div.stButton button span {color: #FFFFFF !important;}
Â  Â  header {visibility: hidden; height: 0px;}
Â  Â  footer {visibility: hidden; height: 0px;}
Â  Â  #MainMenu {visibility: hidden;}
Â  Â Â 
</style>
""", unsafe_allow_html=True)


# --- 2. VariÃ¡veis de Estado e Perguntas PERSONALIZADAS ---
QUESTION_FLOW = [
Â  Â  {"type": "intro", "text": "Antes de comeÃ§armos, vamos configurar o **idioma e o estilo de resposta** do nosso Mentor. Isso garante uma comunicaÃ§Ã£o perfeita!"},
Â  Â  {"type": "select", "question": "Em qual idioma vocÃª prefere que o Mentor de PDI responda?",Â 
Â  Â  Â "key": "lang", "options": ["PortuguÃªs", "InglÃªs", "Espanhol"]},
Â  Â  {"type": "select", "question": "Qual estilo de interaÃ§Ã£o vocÃª prefere?",Â 
Â  Â  Â "key": "style", "options": ["Extrovertido", "Profissional"]},
Â  Â  {"type": "select", "question": "VocÃª prefere respostas com mais ou menos detalhes?",Â 
Â  Â  Â "key": "detail", "options": ["Muito Detalhe", "Direto ao Ponto"]},
Â  Â  {"type": "intro", "text": "Ã“timo! Agora, comeÃ§arei fazendo algumas perguntas sobre vocÃª. Tudo bem?"},
Â  Â  {"type": "input", "question": "Como vocÃª preferiria que eu te chamasse?"},
Â  Â  {"type": "input", "question": "Quantos anos vocÃª tem?"},
Â  Â  {"type": "intro", "text": "Perfeito. Agora, gostaria de explorarmos mais detalhes sobre suas **experiÃªncias educacionais**."},
Â  Â  {"type": "input", "question": "Qual foi o maior nÃ­vel de educaÃ§Ã£o que vocÃª jÃ¡ obteve? (Ex: Bacharelado, Mestrado, PÃ³s-doutorado)"},
Â  Â  {"type": "input", "question": "Em qual instituiÃ§Ã£o vocÃª obteve essa formaÃ§Ã£o?"},
Â  Â  {"type": "input", "question": "Qual foi a sua Ã¡rea de estudo?"},
Â  Â  {"type": "intro", "text": "Entendido. Vamos agora para o bloco de **experiÃªncia profissional**."},
Â  Â  {"type": "input", "question": "VocÃª jÃ¡ trabalhou como jovem aprendiz? Se sim, em qual ano foi sua primeira experiÃªncia nesse formato?"},
Â  Â  {"type": "input", "question": "VocÃª jÃ¡ trabalhou como estagiÃ¡rio(a)? Se sim, em qual ano foi sua primeira experiÃªncia nesse formato?"},
Â  Â  {"type": "input", "question": "VocÃª jÃ¡ trabalhou como funcionÃ¡rio CLT? Se sim, em qual ano foi sua primeira experiÃªncia nesse formato?"},
Â  Â  {"type": "input", "question": "Por favor, cite os nomes das empresas nas quais vocÃª jÃ¡ trabalhou como CLT (separe por vÃ­rgulas)"},
Â  Â  {"type": "input", "question": "VocÃª estÃ¡ trabalhando atualmente? Se sim, cite qual Ã© o nome da sua posiÃ§Ã£o e empresa atuais"},
Â  Â  {"type": "intro", "text": "Para finalizar nosso formulÃ¡rio, vamos focar nos seus **objetivos profissionais**."},
Â  Â  {"type": "input", "question": "Quais sÃ£o os seus principais objetivos profissionais?"}
]
NUM_FLOW_STEPS = len(QUESTION_FLOW)

# --- 3. Carregamento Secreto da Chave ---
gemini_api_key = os.environ.get("GEMINI_API_KEY")

# --- 4. LÃ³gica de MemÃ³ria (HistÃ³rico e Estado) ---
if "messages" not in st.session_state:
Â  Â  clear_session_state()Â 

# --- FUNÃ‡Ã•ES DE GERAÃ‡ÃƒO E DOWNLOAD ---

def get_user_name():
Â  Â  """Busca o nome preferido do usuÃ¡rio no histÃ³rico da conversa."""
Â  Â  name_question = "Como vocÃª preferiria que eu te chamasse?"
Â  Â  for msg in st.session_state.messages:
Â  Â  Â  Â  if msg["role"] == "user" and name_question in msg["content"]:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  name = msg["content"].split(':')[-1].strip()
Â  Â  Â  Â  Â  Â  Â  Â  if name:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return name
Â  Â  Â  Â  Â  Â  except:
Â  Â  Â  Â  Â  Â  Â  Â  pass
Â  Â  return "UsuÃ¡rio(a)"Â 

def format_transcript_data(messages):
Â  Â  """Formata o histÃ³rico de mensagens em uma lista de tuplas (role, content)."""
Â  Â  data = []
Â  Â  user_name = get_user_name()
Â  Â  for msg in messages[1:]:
Â  Â  Â  Â  role = "Mentor" if msg["role"] == "model" else user_name
Â  Â  Â  Â  data.append((role, msg["content"]))
Â  Â  return data

def clean_and_encode_text(text):
Â  Â  """
Â  Â  Limpa o texto de Markdown e garante que qualquer caractere complexo seja substituÃ­do.
Â  Â Â 
Â  Â  CORREÃ‡ÃƒO: Mudar para UTF-8 para melhor suporte a caracteres, pois Latin-1 estÃ¡ falhando.
Â  Â  """
Â  Â  clean = text.replace("`", "'").replace("**", "").replace("*", "")
Â  Â  # Usamos UTF-8 para a limpeza inicial
Â  Â  return clean.encode('utf-8', 'replace').decode('utf-8')

def pdf_print_content(pdf, data):
Â  Â  """Imprime o conteÃºdo formatado no PDF com cores e negrito (SoluÃ§Ã£o EstÃ¡vel)."""
Â  Â Â 
Â  Â  MENTOR_BLUE = (0, 100, 200)Â  Â 
Â  Â  USER_GREEN = (0, 150, 0)Â  Â  Â 
Â  Â  WHITE = (255, 255, 255)Â  Â  Â Â 
Â  Â Â 
Â  Â  for role, content in data:
Â  Â  Â  Â  # Limpeza Ã© feita aqui
Â  Â  Â  Â  clean_content = clean_and_encode_text(content)

Â  Â  Â  Â  # 1. ImpressÃ£o do CabeÃ§alho do Turno
Â  Â  Â  Â  if role == "Mentor":
Â  Â  Â  Â  Â  Â  pdf.set_text_color(*MENTOR_BLUE)
Â  Â  Â  Â  Â  Â  pdf.set_font("Helvetica", style="B", size=11)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  pdf.set_text_color(*USER_GREEN)
Â  Â  Â  Â  Â  Â  pdf.set_font("Helvetica", style="B", size=11)
Â  Â  Â  Â Â 
Â  Â  Â  Â  pdf.cell(0, 8, f"ğŸ—£ï¸ {role}:", ln=1)Â 

Â  Â  Â  Â  # 2. ImpressÃ£o do ConteÃºdo (Texto Limpo)
Â  Â  Â  Â  pdf.set_text_color(*WHITE)
Â  Â  Â  Â  pdf.set_font("Helvetica", size=10)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # CORREÃ‡ÃƒO: Usamos o UTF-8 tambÃ©m aqui, o que aumenta a chance de sucesso
Â  Â  Â  Â  # (mas o problema de fundo estÃ¡ no Latin-1 interno da biblioteca)
Â  Â  Â  Â  pdf.multi_cell(0, 5, clean_content.encode('utf-8', 'replace').decode('utf-8'))
Â  Â  Â  Â Â 
Â  Â  Â  Â  pdf.ln(2)

@st.cache_data(show_spinner="Gerando Resumo da Conversa com o Gemini...")
def generate_summary(history_messages, api_key):
Â  Â  """Gera um resumo da conversa usando o Gemini."""
Â  Â  if not api_key: return "Erro: Chave GEMINI_API_KEY nÃ£o configurada."
Â  Â  try:
Â  Â  Â  Â  client = genai.Client(api_key=api_key)
Â  Â  Â  Â  history_contents = []
Â  Â  Â  Â  for m in history_messages[1:]:
Â  Â  Â  Â  Â  Â  role = 'user' if m['role'] == 'user' else 'model'
Â  Â  Â  Â  Â  Â  content_obj = Content(role=role, parts=[Part.from_text(text=m['content'])])Â 
Â  Â  Â  Â  Â  Â  history_contents.append(content_obj)
Â  Â  Â  Â  summary_prompt = "VocÃª Ã© um Analista de Dados. Dada a conversa a seguir entre um Mentor de PDI e um UsuÃ¡rio, gere um resumo profissional e conciso dos pontos principais, focando nas respostas do usuÃ¡rio (experiÃªncias e objetivos) e na anÃ¡lise/dÃºvidas do Mentor. USE APENAS TEXTO, SEM MARKDOWN OU SÃMBOLOS."
Â  Â  Â  Â  history_contents.append(Content(role='user', parts=[Part.from_text(text=summary_prompt)]))
Â  Â  Â  Â  response = client.models.generate_content(
Â  Â  Â  Â  Â  Â  model='gemini-2.5-flash',Â 
Â  Â  Â  Â  Â  Â  contents=history_contents
Â  Â  Â  Â  )
Â  Â  Â  Â  return response.text
Â  Â  except APIError as e:Â 
Â  Â  Â  Â  return f"Erro na API do Gemini ao gerar resumo: {e}"
Â  Â  except Exception as e:Â 
Â  Â  Â  Â  return f"Ocorreu um erro inesperado ao gerar resumo: {e}"

# --- FUNÃ‡ÃƒO PRINCIPAL DE GERAÃ‡ÃƒO DE PDF (CORRIGIDA) ---
def generate_pdf_bytes(content_data, title_suffix, is_summary=False):
Â  Â  """Gera o PDF com layout escuro, personalizado e estruturado.
Â  Â  Aceita lista de tuplas (transcriÃ§Ã£o) ou string (resumo)."""
Â  Â Â 
Â  Â  # Inicializa FPDF sem o argumento 'encoding' para evitar TypeError.
Â  Â  pdf = FPDF(unit='mm', format='A4', orientation='P')
Â  Â  pdf.set_auto_page_break(auto=True, margin=20)
Â  Â  pdf.add_page()
Â  Â Â 
Â  Â  # --- 1. Fundo Preto (HACK) ---
Â  Â  pdf.set_fill_color(0, 0, 0) # Preto RGB
Â  Â  pdf.rect(0, 0, pdf.w, pdf.h, 'F') # Desenha um retÃ¢ngulo preto em toda a pÃ¡gina

Â  Â  # --- 2. CabeÃ§alho Personalizado (Branco) ---
Â  Â  pdf.set_text_color(255, 255, 255) # Branco
Â  Â  pdf.set_font("Helvetica", style="B", size=18)
Â  Â  pdf.cell(0, 10, "ğŸ¯ Mentor de PDI Inteligente (Gemini)", ln=1, align="C")
Â  Â Â 
Â  Â  pdf.set_font("Helvetica", style="I", size=12)
Â  Â  pdf.cell(0, 7, title_suffix, ln=1, align="C")
Â  Â Â 
Â  Â  pdf.set_font("Helvetica", size=10)
Â  Â  pdf.cell(0, 5, f"Data: {st.session_state.start_time}", ln=1, align="C")
Â  Â  pdf.ln(8)
Â  Â Â 
Â  Â  # --- 3. ConteÃºdo ---
Â  Â Â 
Â  Â  if is_summary:
Â  Â  Â  Â  # Modo Resumo (espera string)
Â  Â  Â  Â  pdf.set_text_color(255, 255, 255)Â 
Â  Â  Â  Â  pdf.set_font("Helvetica", size=11)
Â  Â  Â  Â Â 
Â  Â  Â  Â  clean_summary = clean_and_encode_text(content_data)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # CORREÃ‡ÃƒO: Usa UTF-8 na conversÃ£o do Resumo
Â  Â  Â  Â  pdf.multi_cell(0, 6, clean_summary.encode('utf-8', 'replace').decode('utf-8'))
Â  Â  else:
Â  Â  Â  Â  # Modo TranscriÃ§Ã£o (espera lista de tuplas)
Â  Â  Â  Â  pdf_print_content(pdf, content_data)
Â  Â  Â  Â Â 
Â  Â  # --- 4. SaÃ­da Final (CorreÃ§Ã£o CrÃ­tica para UnicodeEncodeError) ---
Â  Â  # Reaplicamos o Latin-1 replace, pois o erro Ã© na tentativa interna do FPDF de usar Latin-1.
Â  Â  return pdf.output(dest='S').encode('latin-1', 'replace')


# FunÃ§Ã£o que executa o submit do formulÃ¡rio de seleÃ§Ã£o
def submit_form(key, question):
Â  Â  selected_option = st.session_state[f'select_{st.session_state.pdi_state}']
Â  Â  st.session_state.configs[key] = selected_option
Â  Â  st.session_state.messages.append({"role": "user", "content": f"{question}: {selected_option}"})
Â  Â  st.session_state.pdi_state += 1Â 
Â  Â  st.rerun()Â 


# FunÃ§Ã£o para montar o System Prompt baseado nas configuraÃ§Ãµes
def build_system_prompt():
Â  Â  lang = st.session_state.configs.get('lang', 'PortuguÃªs')
Â  Â  style = st.session_state.configs.get('style', 'Profissional')
Â  Â  detail = st.session_state.configs.get('detail', 'Muito Detalhe')
Â  Â Â 
Â  Â  return f"""
Â  Â  Â  Â  VocÃª Ã© um Mentor de Carreira SÃªnior especializado em criar Planos de Desenvolvimento Individual (PDI).
Â  Â  Â  Â Â 
Â  Â  Â  Â  INSTRUÃ‡Ã•ES DE COMPORTAMENTO RÃGIDAS:
Â  Â  Â  Â  1. EDUCAÃ‡ÃƒO: VocÃª **DEVE** ser sempre cortÃªs, educado e profissional. **NUNCA** use linguagem passivo-agressiva ou grosseira, mesmo ao pedir esclarecimentos ou ao criticar objetivos.
Â  Â  Â  Â  2. IDIOMA PRINCIPAL: Responda APENAS em {lang}.
Â  Â  Â  Â  3. TOM E DETALHE: O tom de voz deve ser {style}. Se for 'Direto ao Ponto', use listas e parÃ¡grafos curtos, mantendo a polidez.
Â  Â  Â  Â Â 
Â  Â  Â  Â  SUA MISSÃƒO:
Â  Â  Â  Â  VocÃª acaba de receber as respostas iniciais do usuÃ¡rio. Revise, valide e inicie a fase de identificaÃ§Ã£o de Gaps.
Â  Â  Â  Â  """

# FunÃ§Ã£o para gerar o conteÃºdo usando o Gemini
def generate_gemini_response(prompt, api_key):
Â  Â  st.session_state.messages[0]['content'] = build_system_prompt()
Â  Â  system_prompt = st.session_state.messages[0]['content']

Â  Â  if not api_key: st.error("Erro de configuraÃ§Ã£o: A chave GEMINI_API_KEY nÃ£o foi encontrada."); return None
Â  Â  Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  client = genai.Client(api_key=api_key)
Â  Â  Â  Â Â 
Â  Â  Â  Â  history_messages = []
Â  Â  Â  Â  for m in st.session_state.messages[1:]:
Â  Â  Â  Â  Â  Â  role = 'user' if m['role'] == 'user' else 'model'
Â  Â  Â  Â  Â  Â  content_obj = Content(role=role, parts=[Part.from_text(text=m['content'])])Â 
Â  Â  Â  Â  Â  Â  history_messages.append(content_obj)
Â  Â  Â  Â Â 
Â  Â  Â  Â  history_messages.append(Content(role='user', parts=[Part.from_text(text=prompt)]))

Â  Â  Â  Â  response = client.models.generate_content(
Â  Â  Â  Â  Â  Â  model='gemini-2.5-flash',Â 
Â  Â  Â  Â  Â  Â  contents=history_messages,Â 
Â  Â  Â  Â  Â  Â  config={'system_instruction': system_prompt}Â 
Â  Â  Â  Â  )
Â  Â  Â  Â  return response
Â  Â Â 
Â  Â  except APIError as e: st.error(f"Erro na API do Gemini: Detalhe: {e}"); return None
Â  Â  except Exception as e: st.error(f"Ocorreu um erro inesperado: {e}"); return None


# --- 5. LÃ³gica da MÃ¡quina de Estados (Controle do Fluxo) ---

# Exibir mensagens anteriores no chat
for msg in st.session_state.messages:
Â  Â  if msg["role"] != "system":
Â  Â  Â  Â  role = 'assistant' if msg["role"] == 'model' else msg["role"]
Â  Â  Â  Â  st.chat_message(role).write(msg["content"])


# LÃ³gica para avanÃ§ar o formulÃ¡rio ou iniciar o chat
if st.session_state.pdi_state < NUM_FLOW_STEPS:
Â  Â Â 
Â  Â  current_step = QUESTION_FLOW[st.session_state.pdi_state]
Â  Â Â 
Â  Â  # 5.1. Exibir IntroduÃ§Ã£o E SALVAR NO HISTÃ“RICO
Â  Â  if current_step["type"] == "intro":
Â  Â  Â  Â  intro_text = current_step["text"]
Â  Â  Â  Â  st.chat_message("assistant").write(intro_text)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if not st.session_state.messages or st.session_state.messages[-1]["content"] != intro_text:
Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "model", "content": intro_text})
Â  Â  Â  Â Â 
Â  Â  Â  Â  st.session_state.pdi_state += 1
Â  Â  Â  Â  st.rerun()

Â  Â  # 5.2. Exibir MÃºltipla Escolha (st.radio)
Â  Â  elif current_step["type"] == "select":
Â  Â  Â  Â  question_text = current_step["question"]
Â  Â  Â  Â  st.chat_message("assistant").write(question_text)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if not st.session_state.messages or st.session_state.messages[-1]["content"] != question_text:
Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "model", "content": question_text})

Â  Â  Â  Â  with st.form(key=f'form_{st.session_state.pdi_state}'):
Â  Â  Â  Â  Â  Â  st.radio("Selecione uma opÃ§Ã£o:",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â current_step["options"],Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â key=f'select_{st.session_state.pdi_state}')
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  st.form_submit_button(
Â  Â  Â  Â  Â  Â  Â  Â  "Confirmar e Continuar",Â 
Â  Â  Â  Â  Â  Â  Â  Â  on_click=submit_form,Â 
Â  Â  Â  Â  Â  Â  Â  Â  kwargs={'key': current_step["key"], 'question': current_step["question"]}
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  st.stop()Â 

Â  Â  # 5.3. Exibir Pergunta de Texto (st.chat_input)
Â  Â  elif current_step["type"] == "input":
Â  Â  Â  Â  question_text = current_step["question"]
Â  Â  Â  Â  st.chat_message("assistant").write(question_text)

Â  Â  Â  Â  if not st.session_state.messages or st.session_state.messages[-1]["content"] != question_text:
Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "model", "content": question_text})


# 5.4. Captura a interaÃ§Ã£o do usuÃ¡rio e Finaliza
if prompt := st.chat_input("Digite sua resposta aqui..."):
Â  Â Â 
Â  Â  st.session_state.messages.append({"role": "user", "content": prompt})
Â  Â  st.chat_message("user").write(prompt)

Â  Â  if st.session_state.pdi_state < NUM_FLOW_STEPS:
Â  Â  Â  Â Â 
Â  Â  Â  Â  st.session_state.pdi_state += 1
Â  Â  Â  Â Â 
Â  Â  Â  Â  if st.session_state.pdi_state < NUM_FLOW_STEPS:
Â  Â  Â  Â  Â  Â  st.rerun()Â 
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # TransiÃ§Ã£o final para o Chat Ativo
Â  Â  Â  Â  Â  Â  with st.chat_message("assistant"):
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("âœ… **FormulÃ¡rio inicial completo!** O Mentor de Carreira jÃ¡ estÃ¡ analisando suas respostas. Por favor, aguarde enquanto ele processa a primeira anÃ¡lise e inicia a fase de identificaÃ§Ã£o de *Gaps*.")
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  final_prompt_to_gemini = st.session_state.messages[-1]['content']
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  with st.chat_message("assistant"):
Â  Â  Â  Â  Â  Â  Â  Â  response = generate_gemini_response(final_prompt_to_gemini, gemini_api_key)
Â  Â  Â  Â  Â  Â  Â  Â  if response:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  full_response = response.text
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(full_response)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "model", "content": full_response})
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.pop()
Â  Â  else:
Â  Â  Â  Â  # 5.5. Chat Ativo (Gemini assume)
Â  Â  Â  Â  with st.chat_message("assistant"):
Â  Â  Â  Â  Â  Â  response = generate_gemini_response(prompt, gemini_api_key)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if response:
Â  Â  Â  Â  Â  Â  Â  Â  full_response = response.text
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(full_response)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.append({"role": "model", "content": full_response})
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.messages.pop()

# --- 6. BOTÃ•ES DE AÃ‡ÃƒO E DOWNLOAD (Sempre VisÃ­veis na Sidebar) ---

st.sidebar.subheader("âš™ï¸ AÃ§Ãµes")
st.sidebar.button("Limpar Conversa e RecomeÃ§ar", on_click=clear_session_state)Â 
st.sidebar.markdown("---")


# GeraÃ§Ã£o de PDF (visÃ­vel o tempo todo)
st.sidebar.subheader("ğŸ—‚ï¸ Download do HistÃ³rico")

# TranscriÃ§Ã£o Completa
transcript_data = format_transcript_data(st.session_state.messages)
pdf_full = generate_pdf_bytes(transcript_data, "TranscriÃ§Ã£o Completa", is_summary=False)Â 

st.sidebar.download_button(
Â  Â  label="1ï¸âƒ£ TranscriÃ§Ã£o Completa (PDF)",
Â  Â  data=pdf_full,
Â  Â  file_name=f"PDI_Transcricao_{datetime.now().strftime('%Y%m%d')}.pdf",
Â  Â  mime="application/pdf"
)

# Resumo
if st.sidebar.button("2ï¸âƒ£ Gerar Resumo (PDF)"):
Â  Â Â 
Â  Â  if st.session_state.pdi_state < NUM_FLOW_STEPS:
Â  Â  Â  Â  st.warning("Aguarde a conclusÃ£o do formulÃ¡rio inicial para gerar um resumo significativo.")
Â  Â  elif gemini_api_key:
Â  Â  Â  Â  # Gera o resumo usando a funÃ§Ã£o cacheada
Â  Â  Â  Â  summary_text = generate_summary(st.session_state.messages, gemini_api_key)
Â  Â  Â  Â Â 
Â  Â  Â  Â  if summary_text.startswith(("Erro:", "Ocorreu um erro")):
Â  Â  Â  Â  Â  Â  Â st.error(summary_text)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # O Resumo Ã© uma string simples, o PDF precisa saber que Ã© um resumo
Â  Â  Â  Â  Â  Â  pdf_summary = generate_pdf_bytes(summary_text, "Resumo da AnÃ¡lise (Gemini)", is_summary=True)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Reexibe o botÃ£o com os dados do PDF
Â  Â  Â  Â  Â  Â  st.sidebar.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  label="âœ… Baixar Resumo Gerado",
Â  Â  Â  Â  Â  Â  Â  Â  data=pdf_summary,
Â  Â  Â  Â  Â  Â  Â  Â  file_name=f"PDI_Resumo_{datetime.now().strftime('%Y%m%d')}.pdf",
Â  Â  Â  Â  Â  Â  Â  Â  mime="application/pdf"
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  st.success("Resumo gerado com sucesso! Clique para baixar.")
Â  Â  else:
Â  Â  Â  Â  st.error("Erro: A chave GEMINI_API_KEY nÃ£o estÃ¡ configurada.")

essa versÃ£o Ã© a que funciona corretamente, mas pdf estÃ¡ feio
